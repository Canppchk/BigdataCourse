{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "stopped-sensitivity",
      "metadata": {
        "id": "stopped-sensitivity"
      },
      "source": [
        "# Apache Parquet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "warming-advance",
      "metadata": {
        "id": "warming-advance"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "greek-peter",
      "metadata": {
        "id": "greek-peter"
      },
      "source": [
        "Full Document"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "compatible-sharp",
      "metadata": {
        "id": "compatible-sharp"
      },
      "source": [
        "https://arrow.apache.org/docs/python/parquet.html"
      ]
    },
    {
      "cell_type": "raw",
      "id": "suitable-commons",
      "metadata": {
        "id": "suitable-commons"
      },
      "source": [
        "Three options to install:\n",
        "1. Parquet-tools\n",
        "https://pypi.org/project/parquet-tools/\n",
        "2. parquet python\n",
        "\n",
        "https://pypi.org/project/parquet/\n",
        "\n",
        "3. pyarrow\n",
        "\n",
        "https://arrow.apache.org/docs/python/install.html#using-pip\n",
        "\n",
        "Here I use pyarrow since we can follow some NVIDIA library like rapids.ai later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adjacent-purpose",
      "metadata": {
        "id": "adjacent-purpose"
      },
      "outputs": [],
      "source": [
        "import pyarrow.parquet as pq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "norman-sensitivity",
      "metadata": {
        "id": "norman-sensitivity"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyarrow as pa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "civic-administrator",
      "metadata": {
        "id": "civic-administrator"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'one': [-1, np.nan, 2.5],\n",
        "                   'two': ['foo', 'bar', 'baz'],\n",
        "                   'three': [True, False, True]},\n",
        "                   index=list('abc'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "academic-breath",
      "metadata": {
        "id": "academic-breath"
      },
      "outputs": [],
      "source": [
        "table = pa.Table.from_pandas(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "under-district",
      "metadata": {
        "id": "under-district"
      },
      "outputs": [],
      "source": [
        "pq.write_table(table, 'example.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "searching-mediterranean",
      "metadata": {
        "id": "searching-mediterranean"
      },
      "outputs": [],
      "source": [
        "table2 = pq.read_table('example.parquet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "compliant-project",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "compliant-project",
        "outputId": "24048954-194e-4293-e6ca-5d9108913c92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   one  two  three\n",
              "a -1.0  foo   True\n",
              "b  NaN  bar  False\n",
              "c  2.5  baz   True"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>one</th>\n",
              "      <th>two</th>\n",
              "      <th>three</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>a</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>foo</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b</th>\n",
              "      <td>NaN</td>\n",
              "      <td>bar</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c</th>\n",
              "      <td>2.5</td>\n",
              "      <td>baz</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "table2.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correct-physiology",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "correct-physiology",
        "outputId": "b231b683-80e2-4570-c90a-eb3fcc12f011"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyarrow.Table\n",
              "one: double\n",
              "three: bool\n",
              "----\n",
              "one: [[-1,null,2.5]]\n",
              "three: [[true,false,true]]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "pq.read_table('example.parquet', columns=['one', 'three'])\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "blocked-money",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "blocked-money",
        "outputId": "b7eb28ad-fcbe-4d80-97bc-7df2db541da3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   two\n",
              "a  foo\n",
              "b  bar\n",
              "c  baz"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>two</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>a</th>\n",
              "      <td>foo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b</th>\n",
              "      <td>bar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c</th>\n",
              "      <td>baz</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "pq.read_pandas('example.parquet', columns=['two']).to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "joint-messenger",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joint-messenger",
        "outputId": "a8372e58-389a-4083-93ab-3fa7261c8261"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow._parquet.FileMetaData object at 0x7f5d55393720>\n",
              "  created_by: parquet-cpp-arrow version 8.0.0\n",
              "  num_columns: 4\n",
              "  num_rows: 3\n",
              "  num_row_groups: 1\n",
              "  format_version: 1.0\n",
              "  serialized_size: 2574"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "#inspect meta data file\n",
        "parquet_file = pq.ParquetFile('example.parquet')\n",
        "parquet_file.metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "direct-example",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "direct-example",
        "outputId": "c674ea3b-9c0d-40d8-9774-073c1616dc24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow._parquet.FileMetaData object at 0x7f5d54dc4e50>\n",
              "  created_by: parquet-cpp-arrow version 8.0.0\n",
              "  num_columns: 4\n",
              "  num_rows: 3\n",
              "  num_row_groups: 1\n",
              "  format_version: 1.0\n",
              "  serialized_size: 2574"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "metadata = pq.read_metadata('example.parquet')\n",
        "metadata"
      ]
    },
    {
      "cell_type": "raw",
      "id": "better-capability",
      "metadata": {
        "id": "better-capability"
      },
      "source": [
        "As you can learn more in the Apache Parquet format, a Parquet file consists of multiple row groups. read_table will read all of the row groups and concatenate them into a single table. You can read individual row groups with read_row_group:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "streaming-transcript",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "streaming-transcript",
        "outputId": "0b48bd34-c62c-4567-e580-87577db0f736"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "parquet_file.num_row_groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "desperate-coordinator",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "desperate-coordinator",
        "outputId": "f5f56549-eb5b-4ba7-b580-c216af0ab425"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyarrow.Table\n",
              "one: double\n",
              "two: string\n",
              "three: bool\n",
              "__index_level_0__: string\n",
              "----\n",
              "one: [[-1,null,2.5]]\n",
              "two: [[\"foo\",\"bar\",\"baz\"]]\n",
              "three: [[true,false,true]]\n",
              "__index_level_0__: [[\"a\",\"b\",\"c\"]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "parquet_file.read_row_group(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "theoretical-camping",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "theoretical-camping",
        "outputId": "d1ccba36-3723-4b67-c959-828577d69aa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow._parquet.RowGroupMetaData object at 0x7f5d74cacae0>\n",
              "  num_columns: 4\n",
              "  num_rows: 3\n",
              "  total_byte_size: 282"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "metadata.row_group(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "piano-convert",
      "metadata": {
        "id": "piano-convert"
      },
      "source": [
        "We can similarly write a Parquet file with multiple row groups by using ParquetWriter:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "insured-respondent",
      "metadata": {
        "id": "insured-respondent"
      },
      "outputs": [],
      "source": [
        "with pq.ParquetWriter('example2.parquet', table.schema) as writer:\n",
        "   for i in range(3):\n",
        "      writer.write_table(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unnecessary-struggle",
      "metadata": {
        "id": "unnecessary-struggle"
      },
      "outputs": [],
      "source": [
        "pf2 = pq.ParquetFile('example2.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "different-processing",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "different-processing",
        "outputId": "5fcc0dd9-2254-49a1-f731-7021fbec5ebc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "pf2.num_row_groups"
      ]
    },
    {
      "cell_type": "raw",
      "id": "posted-taxation",
      "metadata": {
        "id": "posted-taxation"
      },
      "source": [
        "Reading types as DictionaryArray:\n",
        "\n",
        "The read_dictionary option in read_table and ParquetDataset will cause columns to be read as DictionaryArray, which will become pandas.Categorical when converted to pandas. This option is only valid for string and binary column types, and it can yield significantly lower memory use and improved performance for columns with many repeated string values.\n",
        "\n",
        "https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "contrary-spank",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "contrary-spank",
        "outputId": "491a100c-b215-479c-98b9-58cff36462d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   two\n",
              "0  bar"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>two</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# data type handling\n",
        "# specify data type\n",
        "table3 = pq.read_table('example.parquet', filters= [ (\"two\", \"in\", {\"bar\"})], columns=['two'], \n",
        "                       read_dictionary=['stringb_c2'])\n",
        "\n",
        "table3.to_pandas()"
      ]
    },
    {
      "cell_type": "raw",
      "id": "moral-words",
      "metadata": {
        "id": "moral-words"
      },
      "source": [
        "Multiple Parquet files constitute a Parquet dataset. These may present in a number of ways:\n",
        "\n",
        "A list of Parquet absolute file paths\n",
        "\n",
        "A directory name containing nested directories defining a partitioned dataset\n",
        "\n",
        "A dataset partitioned by year and month may look like on disk:\n",
        "\n",
        "dataset_name/\n",
        "  year=2007/\n",
        "    month=01/\n",
        "       0.parq\n",
        "       1.parq\n",
        "       ...\n",
        "    month=02/\n",
        "       0.parq\n",
        "       1.parq\n",
        "       ...\n",
        "    month=03/\n",
        "    ...\n",
        "  year=2008/\n",
        "    month=01/\n",
        "    ...\n",
        "  ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "superior-windows",
      "metadata": {
        "id": "superior-windows"
      },
      "outputs": [],
      "source": [
        "#write to many partitions\n",
        "# Local dataset write\n",
        "pq.write_to_dataset(table, root_path='dataset_name',\n",
        "                    partition_cols=['one', 'two'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "computational-history",
      "metadata": {
        "id": "computational-history"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "foster-possible",
      "metadata": {
        "id": "foster-possible"
      },
      "source": [
        "# Parquet and pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "suburban-andrews",
      "metadata": {
        "id": "suburban-andrews"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName(\"PySpark Read Parquet\").getOrCreate()\n",
        "\n",
        "Sampledata =[(\"Ram \",\"\",\"sharma\",\"36636\",\"M\",4000), \n",
        "              (\"Shyam \",\"Aggarwal\",\"\",\"40288\",\"M\",5000),\n",
        "              (\"Tushar \",\"\",\"Garg\",\"42114\",\"M\",5000),\n",
        "              (\"Sarita \",\"Kumar\",\"Jain\",\"39192\",\"F\",5000),\n",
        "              (\"Simran\",\"Gupta\",\"Brown\",\"\",\"F\",-2)]\n",
        "\n",
        "Samplecolumns=[\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
        "dataframe = spark.createDataFrame(Sampledata,Samplecolumns)\n",
        "dataframe.write.mode(\"overwrite\").parquet(\"./Samplepeople.parquet\")"
      ],
      "metadata": {
        "id": "Gq0FgcBStBkQ"
      },
      "id": "Gq0FgcBStBkQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ParDataFrame1 = spark.read.parquet(\"./Samplepeople.parquet\")\n",
        "ParDataFrame1.createOrReplaceTempView(\"ParquetTable\")\n",
        "ParDataFrame1.printSchema()\n",
        "ParDataFrame1.show(truncate = False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9eG80Zks9BQ",
        "outputId": "7fbac92a-ddd9-46af-a812-15e504bbc329"
      },
      "id": "h9eG80Zks9BQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- dob: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|firstname|middlename|lastname|dob  |gender|salary|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|Shyam    |Aggarwal  |        |40288|M     |5000  |\n",
            "|Tushar   |          |Garg    |42114|M     |5000  |\n",
            "|Ram      |          |sharma  |36636|M     |4000  |\n",
            "|Sarita   |Kumar     |Jain    |39192|F     |5000  |\n",
            "|Simran   |Gupta     |Brown   |     |F     |-2    |\n",
            "+---------+----------+--------+-----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unlike-compound",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unlike-compound",
        "outputId": "67e3cf0f-801d-4ba1-83da-1ab240cf4ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- marital: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- default: string (nullable = true)\n",
            " |-- balance: integer (nullable = true)\n",
            " |-- housing: string (nullable = true)\n",
            " |-- loan: string (nullable = true)\n",
            " |-- contact: string (nullable = true)\n",
            " |-- day: integer (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- campaign: integer (nullable = true)\n",
            " |-- pdays: integer (nullable = true)\n",
            " |-- previous: integer (nullable = true)\n",
            " |-- poutcome: string (nullable = true)\n",
            " |-- deposit: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.csv('hdfs://localhost:9000/bank.csv', header = True, inferSchema = True)\n",
        "df.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "proprietary-fifty",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "proprietary-fifty",
        "outputId": "69ef06de-cfe6-4f6c-c9f2-e5430788f54c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- marital: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- default: string (nullable = true)\n",
            " |-- balance: integer (nullable = true)\n",
            " |-- housing: string (nullable = true)\n",
            " |-- loan: string (nullable = true)\n",
            " |-- contact: string (nullable = true)\n",
            " |-- day: integer (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- campaign: integer (nullable = true)\n",
            " |-- pdays: integer (nullable = true)\n",
            " |-- previous: integer (nullable = true)\n",
            " |-- poutcome: string (nullable = true)\n",
            " |-- deposit: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#save to local parquet\n",
        "df.write.mode('overwrite').parquet('./bank.parquet')\n",
        "new_df = spark.read.parquet('./bank.parquet')\n",
        "new_df.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "seeing-license",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seeing-license",
        "outputId": "72382c67-0bde-446e-b974-41e37da023b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- marital: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- default: string (nullable = true)\n",
            " |-- balance: integer (nullable = true)\n",
            " |-- housing: string (nullable = true)\n",
            " |-- loan: string (nullable = true)\n",
            " |-- contact: string (nullable = true)\n",
            " |-- day: integer (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- campaign: integer (nullable = true)\n",
            " |-- pdays: integer (nullable = true)\n",
            " |-- previous: integer (nullable = true)\n",
            " |-- poutcome: string (nullable = true)\n",
            " |-- deposit: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#write to hdfs\n",
        "\n",
        "df.write.mode('overwrite').parquet('hdfs://localhost:9000/bank.parquet')\n",
        " \n",
        "new_df = spark.read.parquet('hdfs://localhost:9000/bank.parquet' )\n",
        "new_df.printSchema()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}